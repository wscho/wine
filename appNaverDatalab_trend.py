import os
import re
import time
from datetime import datetime
from io import BytesIO
from typing import Optional, List

import pandas as pd
import requests
import streamlit as st
import plotly.graph_objects as go

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

from korean_font import configure_korean_font
from web_fonts import inject_noto_sans_kr

# =============================
# Font (Korean)
# =============================
_CHOSEN_FONT = configure_korean_font().name


# =============================
# Google Sheets (XLSX download)
# =============================

DEFAULT_SHEET_URL = "https://docs.google.com/spreadsheets/d/1CHRYjfLEfHOa_6ugtTkR3o3rmPd2mmjDLm71b5TAQb4/edit?usp=drive_link"


def _extract_spreadsheet_id(url: str) -> str:
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", url)
    if not m:
        raise ValueError("êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì—ì„œ ë¬¸ì„œ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return m.group(1)


def _xlsx_export_url(spreadsheet_id: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"


def _is_probably_html(resp: requests.Response) -> bool:
    ctype = (resp.headers.get("Content-Type") or "").lower()
    if "text/html" in ctype:
        return True
    head = resp.content[:200].lstrip().lower()
    return head.startswith(b"<!doctype html") or head.startswith(b"<html")


def download_with_retry(url: str, timeout_s: int = 30, retries: int = 3, backoff_s: float = 0.8) -> requests.Response:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    }
    last_exc: Optional[Exception] = None
    for i in range(retries):
        try:
            resp = requests.get(url, headers=headers, timeout=timeout_s, allow_redirects=True)
            resp.raise_for_status()
            if _is_probably_html(resp):
                raise ValueError("ì‘ë‹µì´ HTMLì…ë‹ˆë‹¤(ê¶Œí•œ/ê³µê°œ ì„¤ì • ë¬¸ì œ ê°€ëŠ¥).")
            return resp
        except Exception as e:
            last_exc = e
            time.sleep(backoff_s * (2**i))
    raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {last_exc}")


@st.cache_data(show_spinner=False)
def fetch_xlsx_as_df(sheet_url: str) -> pd.DataFrame:
    sid = _extract_spreadsheet_id(sheet_url)
    resp = download_with_retry(_xlsx_export_url(sid))
    with BytesIO(resp.content) as bio:
        return pd.read_excel(bio)


# =============================
# Data prep
# =============================

def _make_unique_columns(cols: List[str]) -> List[str]:
    seen = {}
    out = []
    for c in cols:
        name = str(c).strip()
        if name == "" or name.lower() == "nan":
            name = "ì»¬ëŸ¼"
        if name not in seen:
            seen[name] = 0
            out.append(name)
        else:
            seen[name] += 1
            out.append(f"{name}__{seen[name]}")
    return out


def normalize_naver_datalab(df_raw: pd.DataFrame) -> pd.DataFrame:
    if df_raw is None or df_raw.empty:
        raise ValueError("ì‹œíŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    df = df_raw.copy()
    df.columns = _make_unique_columns(list(df.columns))

    date_col = "ë‚ ì§œ" if "ë‚ ì§œ" in df.columns else df.columns[0]
    df = df.dropna(subset=[date_col]).copy()

    s = df[date_col].astype(str).str.strip()
    dt = pd.to_datetime(s, errors="coerce")
    if dt.isna().all():
        dt = pd.to_datetime(s, errors="coerce", format="%Y.%m.%d")
    df = df[dt.notna()].copy()
    df["ë‚ ì§œ"] = dt[dt.notna()].dt.date.astype(str)  # YYYY-MM-DD

    for c in df.columns:
        if c == date_col or c == "ë‚ ì§œ":
            continue
        if isinstance(df[c], pd.DataFrame):
            df[c] = df[c].iloc[:, 0]
        df[c] = pd.to_numeric(df[c], errors="coerce")

    if date_col != "ë‚ ì§œ":
        df = df.drop(columns=[date_col])
    keep = ["ë‚ ì§œ"] + [c for c in df.columns if c != "ë‚ ì§œ"]
    df = df.loc[:, keep].copy()
    df = df.sort_values("ë‚ ì§œ")
    return df


def aggregate(df: pd.DataFrame, freq: str) -> pd.DataFrame:
    out = df.copy()
    out["ë‚ ì§œ_dt"] = pd.to_datetime(out["ë‚ ì§œ"], errors="coerce")
    out = out[out["ë‚ ì§œ_dt"].notna()].copy()

    numeric_cols = [c for c in out.columns if c not in {"ë‚ ì§œ", "ë‚ ì§œ_dt"}]
    for c in numeric_cols:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0.0)

    if freq == "D":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.strftime("%Y-%m-%d")
    elif freq == "M":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.to_period("M").astype(str)
    elif freq == "Y":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.year.astype(int).astype(str)
    else:
        raise ValueError("freqëŠ” 'D','M','Y' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    g = out.groupby("ê¸°ê°„", as_index=False)[numeric_cols].sum()
    cols = ["ê¸°ê°„"] + numeric_cols
    return g.loc[:, cols].copy()


def plot_trend(df: pd.DataFrame, x_col: str, y_cols: List[str], title: str) -> go.Figure:
    fig = go.Figure()
    for c in y_cols:
        fig.add_trace(
            go.Scatter(
                x=df[x_col],
                y=df[c],
                mode="lines+markers",
                name=c,
                line=dict(width=3),
                marker=dict(size=5),
            )
        )
    fig.update_layout(
        title=title,
        height=520,
        margin=dict(l=30, r=20, t=60, b=40),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
        font=dict(family=_CHOSEN_FONT or "Malgun Gothic", size=14),
    )
    fig.update_xaxes(showgrid=False)
    fig.update_yaxes(showgrid=True, gridcolor="rgba(0,0,0,0.08)")
    return fig


# =============================
# Streamlit UI
# =============================

st.set_page_config(page_title="Naver DataLab íŠ¸ë Œë“œ", layout="wide")
inject_noto_sans_kr()
st.title("ğŸ“ˆ Naver DataLab íŠ¸ë Œë“œ ë¶„ì„")

with st.sidebar:
    st.header("ë°ì´í„° ì†ŒìŠ¤")
    sheet_url = st.text_input("êµ¬ê¸€ì‹œíŠ¸ URL", value=DEFAULT_SHEET_URL)
    st.caption("ê³µê°œ/ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì ë³´ê¸° ê°€ëŠ¥'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.divider()

    st.header("ì‹œê°í™” ì„¤ì •")
    default_metric = "í•©ê³„"
    st.caption(f"í•œê¸€ í°íŠ¸: {_CHOSEN_FONT or 'ê°ì§€ ì‹¤íŒ¨(ê¹¨ì§ ì‹œ ë§‘ì€ ê³ ë”•/ë‚˜ëˆ”ê³ ë”• ì„¤ì¹˜ í•„ìš”)'}")


@st.cache_data(show_spinner=True)
def load_and_prepare(url: str) -> pd.DataFrame:
    raw = fetch_xlsx_as_df(url)
    return normalize_naver_datalab(raw)


try:
    df = load_and_prepare(sheet_url)
except Exception as e:
    st.error(f"êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

st.caption(f"ì—…ë°ì´íŠ¸ë¨: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

numeric_candidates = [c for c in df.columns if c != "ë‚ ì§œ"]
if not numeric_candidates:
    st.error("ìˆ«ì ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë‚ ì§œ ì™¸ì— ë¶„ì„í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤)")
    st.stop()

with st.sidebar:
    y_cols = st.multiselect(
        "í‘œì‹œí•  ì§€í‘œ(ë³µìˆ˜ ì„ íƒ)",
        options=numeric_candidates,
        default=[default_metric] if default_metric in numeric_candidates else [numeric_candidates[-1]],
    )

if not y_cols:
    st.warning("í‘œì‹œí•  ì§€í‘œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
    st.stop()

tab_d, tab_m, tab_y = st.tabs(["ì¼ë³„", "ì›”ë³„", "ë…„ë„ë³„"])

with tab_d:
    st.subheader("ì¼ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
    df_d = aggregate(df, "D")
    fig = plot_trend(df_d, "ê¸°ê°„", y_cols, "ì¼ë³„ íŠ¸ë Œë“œ")
    st.plotly_chart(fig, use_container_width=True)
    with st.expander("ë°ì´í„° ë³´ê¸°"):
        st.dataframe(df_d, use_container_width=True, height=360)

with tab_m:
    st.subheader("ì›”ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
    df_m = aggregate(df, "M")
    fig = plot_trend(df_m, "ê¸°ê°„", y_cols, "ì›”ë³„ íŠ¸ë Œë“œ")
    st.plotly_chart(fig, use_container_width=True)
    with st.expander("ë°ì´í„° ë³´ê¸°"):
        st.dataframe(df_m, use_container_width=True, height=360)

with tab_y:
    st.subheader("ë…„ë„ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
    df_y = aggregate(df, "Y")
    fig = plot_trend(df_y, "ê¸°ê°„", y_cols, "ë…„ë„ë³„ íŠ¸ë Œë“œ")
    st.plotly_chart(fig, use_container_width=True)
    with st.expander("ë°ì´í„° ë³´ê¸°"):
        st.dataframe(df_y, use_container_width=True, height=360)


