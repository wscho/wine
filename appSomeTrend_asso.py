import os
import re
import time
from datetime import datetime
from io import BytesIO
from typing import Optional

import numpy as np
import pandas as pd
import requests
import streamlit as st

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib.patheffects as pe
import matplotlib.patches as mpatches
import networkx as nx

from korean_font import configure_korean_font
from web_fonts import inject_noto_sans_kr


# =============================
# Font (Korean)
# =============================

_KOREAN_FONT_PROP: Optional[fm.FontProperties] = None

_font_info = configure_korean_font()
_CHOSEN_FONT = _font_info.name
_KOREAN_FONT_PROP = _font_info.prop


# =============================
# Google Sheets (XLSX download)
# =============================

DEFAULT_SHEET_URL = "https://docs.google.com/spreadsheets/d/1ZtqETyVVwcK5RJ-XyNxQeMY8L2MUqew-eRhA6Ik-OnI/edit?usp=sharing"


def _extract_spreadsheet_id(url: str) -> str:
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", url)
    if not m:
        raise ValueError("êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì—ì„œ ë¬¸ì„œ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return m.group(1)


def _xlsx_export_url(spreadsheet_id: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"


def _is_probably_html(resp: requests.Response) -> bool:
    ctype = (resp.headers.get("Content-Type") or "").lower()
    if "text/html" in ctype:
        return True
    head = resp.content[:200].lstrip().lower()
    return head.startswith(b"<!doctype html") or head.startswith(b"<html")


def download_with_retry(url: str, timeout_s: int = 30, retries: int = 3, backoff_s: float = 0.8) -> requests.Response:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    }
    last_exc: Optional[Exception] = None
    for i in range(retries):
        try:
            resp = requests.get(url, headers=headers, timeout=timeout_s, allow_redirects=True)
            resp.raise_for_status()
            if _is_probably_html(resp):
                raise ValueError("ì‘ë‹µì´ HTMLì…ë‹ˆë‹¤(ê¶Œí•œ/ê³µê°œ ì„¤ì • ë¬¸ì œ ê°€ëŠ¥).")
            return resp
        except Exception as e:
            last_exc = e
            time.sleep(backoff_s * (2**i))
    raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {last_exc}")


@st.cache_data(show_spinner=False)
def fetch_xlsx_as_df(sheet_url: str) -> pd.DataFrame:
    sid = _extract_spreadsheet_id(sheet_url)
    resp = download_with_retry(_xlsx_export_url(sid))
    with BytesIO(resp.content) as bio:
        return pd.read_excel(bio)


# =============================
# Parsing
# =============================

def parse_asso(df: pd.DataFrame) -> pd.DataFrame:
    required = {"ì—°ê´€ì–´", "ê±´ìˆ˜", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜", "ë…„ë„"}
    missing = sorted(list(required - set(df.columns)))
    if missing:
        raise ValueError(f"ì—°ê´€ì–´í†µí•©: í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}. í˜„ì¬ ì»¬ëŸ¼={list(df.columns)}")

    out = df.dropna(how="all").copy()
    out["ë…„ë„"] = pd.to_numeric(out["ë…„ë„"], errors="coerce")
    out = out[out["ë…„ë„"].notna()].copy()
    out["ë…„ë„"] = out["ë…„ë„"].astype(int)
    out["ê±´ìˆ˜"] = pd.to_numeric(out["ê±´ìˆ˜"], errors="coerce").fillna(0.0)
    out["ì—°ê´€ì–´"] = out["ì—°ê´€ì–´"].astype(str).str.strip()
    out["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"] = out["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"].astype(str).str.strip()
    out = out[(out["ì—°ê´€ì–´"] != "") & (out["ì—°ê´€ì–´"].str.lower() != "nan")].copy()
    return out


def summarize_all_years(df: pd.DataFrame) -> pd.DataFrame:
    """
    'ì „ì²´' ì„ íƒ ì‹œ:
    - ì—°ê´€ì–´ë³„ ê±´ìˆ˜ í•©ê³„
    - ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜ëŠ” ì—°ê´€ì–´-ì¹´í…Œê³ ë¦¬ ì¡°í•© ì¤‘ ê±´ìˆ˜ í•©ì´ ê°€ì¥ í° ì¹´í…Œê³ ë¦¬ë¥¼ ëŒ€í‘œê°’ìœ¼ë¡œ ì„ íƒ
    """
    tmp = df.groupby(["ì—°ê´€ì–´", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"], as_index=False)["ê±´ìˆ˜"].sum()
    tmp = tmp.sort_values(["ì—°ê´€ì–´", "ê±´ìˆ˜"], ascending=[True, False])
    # ëŒ€í‘œ ì¹´í…Œê³ ë¦¬ë§Œ ë‚¨ê¸°ê³ , ê±´ìˆ˜ëŠ” "ì—°ê´€ì–´ë³„ ì´í•©" í•˜ë‚˜ë¡œ í™•ì •í•œë‹¤.
    best_cat = tmp.drop_duplicates(subset=["ì—°ê´€ì–´"], keep="first")[["ì—°ê´€ì–´", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"]].copy()
    total = df.groupby(["ì—°ê´€ì–´"], as_index=False)["ê±´ìˆ˜"].sum()
    out = best_cat.merge(total, on="ì—°ê´€ì–´", how="left")
    out["ë…„ë„"] = -1
    return out[["ì—°ê´€ì–´", "ê±´ìˆ˜", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜", "ë…„ë„"]]


# =============================
# UI / Graph
# =============================

st.set_page_config(page_title="ì¸íŠ¸ë Œë“œ ì—°ê´€ì„± ë¶„ì„", layout="wide")
inject_noto_sans_kr()
st.title("ğŸ•¸ï¸ ì¸íŠ¸ë Œë“œ ì—°ê´€ì„± ë¶„ì„")

with st.sidebar:
    st.header("ë°ì´í„° ì†ŒìŠ¤")
    sheet_url = st.text_input("êµ¬ê¸€ì‹œíŠ¸ URL", value=DEFAULT_SHEET_URL)
    st.caption("ê³µê°œ/ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì ë³´ê¸° ê°€ëŠ¥'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.divider()

    st.header("í•„í„°/ë ˆì´ì•„ì›ƒ")
    top_n = st.slider("í‘œì‹œ ì—°ê´€ì–´ ìˆ˜", 10, 200, 80, 5)
    k_val = st.slider("ë…¸ë“œ ê°„ê²©(k)", 0.8, 4.0, 2.0, 0.1)
    iters = st.slider("ë ˆì´ì•„ì›ƒ ë°˜ë³µ(iterations)", 50, 600, 220, 10)
    node_mul = st.slider("ë…¸ë“œ í¬ê¸° ë°°ìˆ˜", 0.5, 3.0, 1.2, 0.1)
    st.caption(f"í•œê¸€ í°íŠ¸: {_CHOSEN_FONT or 'ê°ì§€ ì‹¤íŒ¨(ê¹¨ì§ ì‹œ ë§‘ì€ ê³ ë”•/ë‚˜ëˆ”ê³ ë”• ì„¤ì¹˜ í•„ìš”)'}")

    if st.button("ë°ì´í„° ìƒˆë¡œê³ ì¹¨(ìºì‹œ ì‚­ì œ)"):
        st.cache_data.clear()


try:
    raw = fetch_xlsx_as_df(sheet_url)
    df = parse_asso(raw)
except Exception as e:
    st.error(f"êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

st.caption(f"ì—…ë°ì´íŠ¸ë¨: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

years = sorted(df["ë…„ë„"].unique().tolist())
year_options = ["ì „ì²´"] + [str(y) for y in years]
year_sel = st.selectbox("ë…„ë„ ì„ íƒ", year_options, index=len(year_options) - 1, key="asso_year_sel")

if year_sel == "ì „ì²´":
    df_view = summarize_all_years(df)
    title_year = "ì „ì²´"
else:
    year_int = int(year_sel)
    df_view = df[df["ë…„ë„"] == year_int].copy()
    title_year = f"{year_int}ë…„"

df_view = df_view.sort_values("ê±´ìˆ˜", ascending=False).head(top_n)

center = "K-Wine"
G = nx.Graph()
G.add_node(center, category="CENTER", count=float(df_view["ê±´ìˆ˜"].sum()) if len(df_view) else 1.0)

cats = sorted([c for c in df_view["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"].dropna().unique().tolist() if str(c) != ""])
palette = plt.get_cmap("Set3")
cmap = {cat: palette(i % getattr(palette, "N", 12)) for i, cat in enumerate(cats)}

for _, r in df_view.iterrows():
    w = str(r["ì—°ê´€ì–´"]).strip()
    if not w or w.lower() == "nan":
        continue
    cnt = float(r["ê±´ìˆ˜"])
    cat = str(r["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"]).strip()
    G.add_node(w, category=cat, count=cnt)
    G.add_edge(center, w, weight=cnt)

if G.number_of_nodes() <= 1:
    st.info("í‘œì‹œí•  ì—°ê´€ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ)")
    st.stop()

init_pos = {center: np.array([0.0, 0.0])}
pos = nx.spring_layout(G, seed=42, k=float(k_val), iterations=int(iters), pos=init_pos, fixed=[center])

node_colors, node_sizes, labels = [], [], {}
max_cnt = max([d.get("count", 1.0) for n, d in G.nodes(data=True) if n != center] + [1.0])

for n, d in G.nodes(data=True):
    if n == center:
        node_colors.append("#1f1f1f")
        node_sizes.append(3200 * float(node_mul))
        labels[n] = n
    else:
        node_colors.append(cmap.get(d.get("category", ""), "gray"))
        c = float(d.get("count", 0.0))
        node_sizes.append((550 + 2800 * (c / max_cnt)) * float(node_mul))
        labels[n] = f"{n}\n({int(round(c))})"

weights = [float(G[u][v].get("weight", 1.0)) for u, v in G.edges()]
max_w = max(weights) if weights else 1.0
edge_w = [0.6 + 3.2 * (w / max_w) for w in weights]

fig, ax = plt.subplots(figsize=(18, 10), facecolor="white")
ax.set_facecolor("white")
ax.axis("off")

nx.draw_networkx_edges(G, pos, ax=ax, width=edge_w, alpha=0.22, edge_color="#9aa0a6")
nx.draw_networkx_nodes(
    G,
    pos,
    ax=ax,
    node_color=node_colors,
    node_size=node_sizes,
    linewidths=1.2,
    edgecolors="#4a4a4a",
)

font_prop = _KOREAN_FONT_PROP
for n, (x, y) in pos.items():
    is_center = n == center
    ax.text(
        x,
        y,
        labels.get(n, n),
        ha="center",
        va="center",
        fontsize=16 if is_center else 11,
        fontweight="bold" if is_center else "normal",
        color="white" if is_center else "#111111",
        fontproperties=font_prop,
        path_effects=[
            pe.withStroke(linewidth=3.5, foreground="black") if is_center else pe.withStroke(linewidth=3.0, foreground="white")
        ],
    )

handles = [mpatches.Patch(color=cmap[cat], label=cat) for cat in cats]
if handles:
    ax.legend(
        handles=handles,
        title="ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜",
        loc="lower left",
        frameon=True,
        facecolor="white",
        edgecolor="#dddddd",
        framealpha=0.95,
    )

ax.set_title(f"{title_year} K-Wine ì—°ê´€ì–´ ë„¤íŠ¸ì›Œí¬", fontsize=18, fontweight="bold", pad=15)
plt.tight_layout()
st.pyplot(fig)
plt.close(fig)

with st.expander("ì›ë³¸/í•„í„° ë°ì´í„° ë³´ê¸°"):
    st.dataframe(df_view.reset_index(drop=True), use_container_width=True, height=380)


