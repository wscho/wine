# -*- coding: utf-8 -*-
import os
import re
import time
from datetime import datetime
from io import BytesIO
from typing import Optional

import numpy as np
import pandas as pd
import requests
import streamlit as st
import streamlit.components.v1 as components

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl
import matplotlib.patheffects as pe
import matplotlib.patches as mpatches
import networkx as nx

from korean_font import configure_korean_font, korean_font_help_markdown, korean_font_debug_line
from web_fonts import inject_noto_sans_kr


# =============================
# Font (Korean)
# =============================

_KOREAN_FONT_PROP: Optional[fm.FontProperties] = None

_font_info = configure_korean_font()
_CHOSEN_FONT = _font_info.name
_KOREAN_FONT_PROP = _font_info.prop
_KOREAN_FONT_FILE = _font_info.regular_path or _font_info.bold_path


# =============================
# Google Sheets (XLSX download)
# =============================

DEFAULT_SHEET_URL = "https://docs.google.com/spreadsheets/d/1ZtqETyVVwcK5RJ-XyNxQeMY8L2MUqew-eRhA6Ik-OnI/edit?usp=sharing"


def _extract_spreadsheet_id(url: str) -> str:
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", url)
    if not m:
        raise ValueError("êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì—ì„œ ë¬¸ì„œ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return m.group(1)


def _xlsx_export_url(spreadsheet_id: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"


def _is_probably_html(resp: requests.Response) -> bool:
    ctype = (resp.headers.get("Content-Type") or "").lower()
    if "text/html" in ctype:
        return True
    head = resp.content[:200].lstrip().lower()
    return head.startswith(b"<!doctype html") or head.startswith(b"<html")


def download_with_retry(url: str, timeout_s: int = 30, retries: int = 3, backoff_s: float = 0.8) -> requests.Response:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    }
    last_exc: Optional[Exception] = None
    for i in range(retries):
        try:
            resp = requests.get(url, headers=headers, timeout=timeout_s, allow_redirects=True)
            resp.raise_for_status()
            if _is_probably_html(resp):
                raise ValueError("ì‘ë‹µì´ HTMLì…ë‹ˆë‹¤(ê¶Œí•œ/ê³µê°œ ì„¤ì • ë¬¸ì œ ê°€ëŠ¥).")
            return resp
        except Exception as e:
            last_exc = e
            time.sleep(backoff_s * (2**i))
    raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {last_exc}")


@st.cache_data(show_spinner=False)
def fetch_xlsx_as_df(sheet_url: str) -> pd.DataFrame:
    sid = _extract_spreadsheet_id(sheet_url)
    resp = download_with_retry(_xlsx_export_url(sid))
    with BytesIO(resp.content) as bio:
        return pd.read_excel(bio)


# =============================
# Parsing
# =============================

def parse_asso(df: pd.DataFrame) -> pd.DataFrame:
    required = {"ì—°ê´€ì–´", "ê±´ìˆ˜", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜", "ë…„ë„"}
    missing = sorted(list(required - set(df.columns)))
    if missing:
        raise ValueError(f"ì—°ê´€ì–´í†µí•©: í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}. í˜„ì¬ ì»¬ëŸ¼={list(df.columns)}")

    out = df.dropna(how="all").copy()
    out["ë…„ë„"] = pd.to_numeric(out["ë…„ë„"], errors="coerce")
    out = out[out["ë…„ë„"].notna()].copy()
    out["ë…„ë„"] = out["ë…„ë„"].astype(int)
    out["ê±´ìˆ˜"] = pd.to_numeric(out["ê±´ìˆ˜"], errors="coerce").fillna(0.0)
    out["ì—°ê´€ì–´"] = out["ì—°ê´€ì–´"].astype(str).str.strip()
    out["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"] = out["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"].astype(str).str.strip()
    out = out[(out["ì—°ê´€ì–´"] != "") & (out["ì—°ê´€ì–´"].str.lower() != "nan")].copy()
    return out


def summarize_all_years(df: pd.DataFrame) -> pd.DataFrame:
    """
    'ì „ì²´' ì„ íƒ ì‹œ:
    - ì—°ê´€ì–´ë³„ ê±´ìˆ˜ í•©ê³„
    - ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜ëŠ” ì—°ê´€ì–´-ì¹´í…Œê³ ë¦¬ ì¡°í•© ì¤‘ ê±´ìˆ˜ í•©ì´ ê°€ì¥ í° ì¹´í…Œê³ ë¦¬ë¥¼ ëŒ€í‘œê°’ìœ¼ë¡œ ì„ íƒ
    """
    tmp = df.groupby(["ì—°ê´€ì–´", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"], as_index=False)["ê±´ìˆ˜"].sum()
    tmp = tmp.sort_values(["ì—°ê´€ì–´", "ê±´ìˆ˜"], ascending=[True, False])
    # ëŒ€í‘œ ì¹´í…Œê³ ë¦¬ë§Œ ë‚¨ê¸°ê³ , ê±´ìˆ˜ëŠ” "ì—°ê´€ì–´ë³„ ì´í•©" í•˜ë‚˜ë¡œ í™•ì •í•œë‹¤.
    best_cat = tmp.drop_duplicates(subset=["ì—°ê´€ì–´"], keep="first")[["ì—°ê´€ì–´", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"]].copy()
    total = df.groupby(["ì—°ê´€ì–´"], as_index=False)["ê±´ìˆ˜"].sum()
    out = best_cat.merge(total, on="ì—°ê´€ì–´", how="left")
    out["ë…„ë„"] = -1
    return out[["ì—°ê´€ì–´", "ê±´ìˆ˜", "ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜", "ë…„ë„"]]


# =============================
# UI / Graph
# =============================

st.set_page_config(page_title="ì¸íŠ¸ë Œë“œ ì—°ê´€ì„± ë¶„ì„", layout="wide")
inject_noto_sans_kr()
st.title("ğŸ•¸ï¸ ì¸íŠ¸ë Œë“œ ì—°ê´€ì„± ë¶„ì„")

if not _KOREAN_FONT_PROP:
    st.error("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°°í¬ í™˜ê²½ì—ì„œëŠ” ë…¸ë“œ ë¼ë²¨ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆì–´ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
    st.markdown(korean_font_help_markdown())
    st.stop()

with st.sidebar:
    st.header("ë°ì´í„° ì†ŒìŠ¤")
    sheet_url = st.text_input("êµ¬ê¸€ì‹œíŠ¸ URL", value=DEFAULT_SHEET_URL)
    st.caption("ê³µê°œ/ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì ë³´ê¸° ê°€ëŠ¥'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.divider()

    st.header("í•„í„°/ë ˆì´ì•„ì›ƒ")
    top_n = st.slider("í‘œì‹œ ì—°ê´€ì–´ ìˆ˜", 10, 200, 80, 5)
    k_val = st.slider("ë…¸ë“œ ê°„ê²©(k)", 0.8, 4.0, 2.0, 0.1)
    iters = st.slider("ë ˆì´ì•„ì›ƒ ë°˜ë³µ(iterations)", 50, 600, 220, 10)
    node_mul = st.slider("ë…¸ë“œ í¬ê¸° ë°°ìˆ˜", 0.5, 3.0, 1.2, 0.1)
    if _KOREAN_FONT_FILE:
        st.caption(f"í•œê¸€ í°íŠ¸: {_CHOSEN_FONT} (íŒŒì¼ ì‚¬ìš©)")
        st.caption(korean_font_debug_line(_font_info))
    else:
        st.caption(f"í•œê¸€ í°íŠ¸: {_CHOSEN_FONT or 'ê°ì§€ ì‹¤íŒ¨'}")

    if st.button("ë°ì´í„° ìƒˆë¡œê³ ì¹¨(ìºì‹œ ì‚­ì œ)"):
        st.cache_data.clear()


try:
    raw = fetch_xlsx_as_df(sheet_url)
    df = parse_asso(raw)
except Exception as e:
    st.error(f"êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

st.caption(f"ì—…ë°ì´íŠ¸ë¨: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

years = sorted(df["ë…„ë„"].unique().tolist())
year_options = ["ì „ì²´"] + [str(y) for y in years]
year_sel = st.selectbox("ë…„ë„ ì„ íƒ", year_options, index=len(year_options) - 1, key="asso_year_sel")

if year_sel == "ì „ì²´":
    df_view = summarize_all_years(df)
    title_year = "ì „ì²´"
else:
    year_int = int(year_sel)
    df_view = df[df["ë…„ë„"] == year_int].copy()
    title_year = f"{year_int}ë…„"

df_view = df_view.sort_values("ê±´ìˆ˜", ascending=False).head(top_n)

center = "K-Wine"
G = nx.Graph()
G.add_node(center, category="CENTER", count=float(df_view["ê±´ìˆ˜"].sum()) if len(df_view) else 1.0)

cats = sorted([c for c in df_view["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"].dropna().unique().tolist() if str(c) != ""])
palette = plt.get_cmap("Set3")
cmap = {cat: palette(i % getattr(palette, "N", 12)) for i, cat in enumerate(cats)}

for _, r in df_view.iterrows():
    w = str(r["ì—°ê´€ì–´"]).strip()
    if not w or w.lower() == "nan":
        continue
    cnt = float(r["ê±´ìˆ˜"])
    cat = str(r["ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜"]).strip()
    G.add_node(w, category=cat, count=cnt)
    G.add_edge(center, w, weight=cnt)

if G.number_of_nodes() <= 1:
    st.info("í‘œì‹œí•  ì—°ê´€ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ)")
    st.stop()

init_pos = {center: np.array([0.0, 0.0])}
pos = nx.spring_layout(G, seed=42, k=float(k_val), iterations=int(iters), pos=init_pos, fixed=[center])

node_colors, node_sizes, labels = [], [], {}
max_cnt = max([d.get("count", 1.0) for n, d in G.nodes(data=True) if n != center] + [1.0])

for n, d in G.nodes(data=True):
    if n == center:
        # ì¤‘ì•™ ë…¸ë“œëŠ” ë¼ë²¨ì„ "ê²€ì •"ìœ¼ë¡œ ì“°ê¸° ìœ„í•´ ë°°ê²½ì„ ë°ê²Œ
        node_colors.append("#ffffff")
        node_sizes.append(3200 * float(node_mul))
        labels[n] = n
    else:
        node_colors.append(cmap.get(d.get("category", ""), "gray"))
        c = float(d.get("count", 0.0))
        node_sizes.append((550 + 2800 * (c / max_cnt)) * float(node_mul))
        labels[n] = f"{n}\n({int(round(c))})"

weights = [float(G[u][v].get("weight", 1.0)) for u, v in G.edges()]
max_w = max(weights) if weights else 1.0
edge_w = [0.6 + 3.2 * (w / max_w) for w in weights]

# ì„ ëª…ë„ ê°œì„ :
# - ê¸°ë³¸ì€ SVG(ë²¡í„°)ë¡œ ë Œë”ë§í•´ í™•ëŒ€/ì¶•ì†Œ ì‹œì—ë„ ê¸€ìê°€ ì„ ëª…í•˜ë„ë¡ í‘œì‹œ
# - SVG ì‹¤íŒ¨ ì‹œ ë” ë†’ì€ DPI PNGë¡œ fallback
FIG_DPI = 480
fig, ax = plt.subplots(figsize=(18, 10), facecolor="white", dpi=FIG_DPI)
ax.set_facecolor("white")
ax.axis("off")

nx.draw_networkx_edges(G, pos, ax=ax, width=edge_w, alpha=0.08, edge_color="#9aa0a6")
nx.draw_networkx_nodes(
    G,
    pos,
    ax=ax,
    node_color=node_colors,
    node_size=node_sizes,
    linewidths=1.4,
    edgecolors="#4a4a4a",
)

font_prop = _KOREAN_FONT_PROP
for n, (x, y) in pos.items():
    is_center = n == center
    ax.text(
        x,
        y,
        labels.get(n, n),
        ha="center",
        va="center",
        # ê°€ë…ì„± ê°œì„ : ë¼ë²¨ í¬ê¸° 2ë°° + ë³¼ë“œ + ê²€ì •ìƒ‰
        # ìš”ì²­: ê¸°ì¡´ ëŒ€ë¹„ ì•½ 20% ì¶•ì†Œ
        # ìš”ì²­: sometrend asso ê·¸ë˜í”„ì˜ ëª¨ë“  ê¸€ì 30% ì¶•ì†Œ(= 0.7ë°°)
        fontsize=18 if is_center else 13,
        fontweight="bold",
        # ìš”ì²­: ê¸€ììƒ‰ì„ ì§„í•œ íŒŒë€ìƒ‰ìœ¼ë¡œ
        color="#0B1F66",
        fontproperties=font_prop,
        # ë°°ê²½/ì—£ì§€ì™€ ê²¹ì³ë„ ì„ ëª…í•˜ê²Œ ë³´ì´ë„ë¡ í°ìƒ‰ ì™¸ê³½ì„  + ë³¸ë¬¸ì„ ë¶„ë¦¬(Stroke + Normal)
        # withStroke()ë³´ë‹¤ ê²½ê³„ê°€ ë˜ë ·í•˜ê²Œ ë³´ì´ëŠ” ê²½ìš°ê°€ ë§ìŒ
        path_effects=[
            pe.Stroke(linewidth=2.8 if is_center else 2.4, foreground="white"),
            pe.Normal(),
        ],
        zorder=10,
    )

handles = [mpatches.Patch(color=cmap[cat], label=cat) for cat in cats]
if handles:
    ax.legend(
        handles=handles,
        title="ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜",
        loc="lower left",
        frameon=True,
        facecolor="white",
        edgecolor="#dddddd",
        framealpha=0.95,
    )
    # ë²”ë¡€ í…ìŠ¤íŠ¸ë„ ë³¼ë“œë¡œ (ê°€ë…ì„±)
    leg = ax.get_legend()
    if leg is not None:
        # ìš”ì²­: ê·¸ë˜í”„ì˜ ëª¨ë“  ê¸€ì 30% ì¶•ì†Œ(= 0.7ë°°)
        legend_fs = 13
        legend_title_fs = 14
        for t in leg.get_texts():
            t.set_fontweight("bold")
            t.set_fontsize(legend_fs)
        if leg.get_title() is not None:
            leg.get_title().set_fontweight("bold")
            leg.get_title().set_fontsize(legend_title_fs)

ax.set_title(f"{title_year} K-Wine ì—°ê´€ì–´ ë„¤íŠ¸ì›Œí¬", fontsize=13, fontweight="bold", pad=15, color="#0B1F66")
plt.tight_layout()
_orig_svg_fonttype = mpl.rcParams.get("svg.fonttype", "path")
try:
    # SVGì—ì„œ í°íŠ¸ ë¬¸ì œë¥¼ í”¼í•˜ë ¤ê³  í…ìŠ¤íŠ¸ë¥¼ pathë¡œ ë³€í™˜(í´ë¼ì´ì–¸íŠ¸ì— í°íŠ¸ê°€ ì—†ì–´ë„ ê¹¨ì§€ì§€ ì•ŠìŒ)
    mpl.rcParams["svg.fonttype"] = "path"
    with BytesIO() as bio:
        fig.savefig(bio, format="svg", facecolor="white", bbox_inches="tight", pad_inches=0.2)
        svg = bio.getvalue().decode("utf-8", errors="ignore")
    components.html(
        "<style>"
        "svg{shape-rendering:geometricPrecision;text-rendering:geometricPrecision;}"
        "path{shape-rendering:geometricPrecision;}"
        "</style>"
        f"<div style='width:100%; overflow:auto'>{svg}</div>",
        height=760,
        scrolling=True,
    )
except Exception:
    # fallback: ê³ DPI PNG
    with BytesIO() as bio:
        fig.savefig(bio, format="png", dpi=FIG_DPI, facecolor="white", bbox_inches="tight", pad_inches=0.2)
        bio.seek(0)
        st.image(bio.getvalue(), use_container_width=True)
finally:
    try:
        mpl.rcParams["svg.fonttype"] = _orig_svg_fonttype
    except Exception:
        pass
plt.close(fig)

with st.expander("ì›ë³¸/í•„í„° ë°ì´í„° ë³´ê¸°"):
    st.dataframe(df_view.reset_index(drop=True), use_container_width=True, height=380)


