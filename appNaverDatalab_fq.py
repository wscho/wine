# -*- coding: utf-8 -*-
import os
import re
import time
from datetime import datetime
from io import BytesIO
from pathlib import Path
from typing import Optional, List

import pandas as pd
import requests
import streamlit as st

import plotly.graph_objects as go

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

from korean_font import configure_korean_font
from web_fonts import inject_noto_sans_kr


# =============================
# Font (Korean)
# =============================
_CHOSEN_FONT = configure_korean_font().name


# =============================
# Google Sheets (XLSX download)
# =============================

# ë„¤ì´ë²„ì–¸ê¸‰ëŸ‰ ë°ì´í„°ì…‹
DEFAULT_SHEET_URL = "https://docs.google.com/spreadsheets/d/1CHRYjfLEfHOa_6ugtTkR3o3rmPd2mmjDLm71b5TAQb4/edit?usp=drive_link"

# ë„¤ì´ë²„ DataLab ë¹„êµ(êµ­ë‚´/í•´ì™¸/êµ­ê°€ë³„ ì™€ì¸) ë°ì´í„°ì…‹
# - 7í–‰: í•„ë“œëª…, 8í–‰ë¶€í„° ë°ì´í„°
DEFAULT_COMP_SHEET_URL = "https://docs.google.com/spreadsheets/d/1amDCFWC95S2dVImacl-41Uq9XYQr_fyD/edit?usp=sharing&ouid=112643056517438341912&rtpof=true&sd=true"


def _extract_spreadsheet_id(url: str) -> str:
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", url)
    if not m:
        raise ValueError("êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì—ì„œ ë¬¸ì„œ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return m.group(1)


def _xlsx_export_url(spreadsheet_id: str) -> str:
    # gid ì—†ì´ ë¬¸ì„œ ì „ì²´ë¥¼ xlsxë¡œ export (ê¶Œí•œ/ë¦¬ë‹¤ì´ë ‰íŠ¸ ì´ìŠˆ ì™„í™”)
    return f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"


def _is_probably_html(resp: requests.Response) -> bool:
    ctype = (resp.headers.get("Content-Type") or "").lower()
    if "text/html" in ctype:
        return True
    head = resp.content[:200].lstrip().lower()
    return head.startswith(b"<!doctype html") or head.startswith(b"<html")


def download_with_retry(url: str, timeout_s: int = 30, retries: int = 3, backoff_s: float = 0.8) -> requests.Response:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    }
    last_exc: Optional[Exception] = None
    for i in range(retries):
        try:
            resp = requests.get(url, headers=headers, timeout=timeout_s, allow_redirects=True)
            resp.raise_for_status()
            if _is_probably_html(resp):
                raise ValueError("ì‘ë‹µì´ HTMLì…ë‹ˆë‹¤(ê¶Œí•œ/ê³µê°œ ì„¤ì • ë¬¸ì œ ê°€ëŠ¥).")
            return resp
        except Exception as e:
            last_exc = e
            time.sleep(backoff_s * (2**i))
    raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {last_exc}")


@st.cache_data(show_spinner=False)
def fetch_xlsx_as_df(sheet_url: str) -> pd.DataFrame:
    sid = _extract_spreadsheet_id(sheet_url)
    resp = download_with_retry(_xlsx_export_url(sid))
    with BytesIO(resp.content) as bio:
        return pd.read_excel(bio)


@st.cache_data(show_spinner=False)
def fetch_xlsx_as_df_with_header(sheet_url: str, header_row_1based: int) -> pd.DataFrame:
    """
    header_row_1based: 1ë¶€í„° ì‹œì‘í•˜ëŠ” í—¤ë” í–‰ ë²ˆí˜¸ (ì˜ˆ: 7í–‰ì´ í—¤ë”ë©´ 7)
    """
    sid = _extract_spreadsheet_id(sheet_url)
    resp = download_with_retry(_xlsx_export_url(sid))
    header0 = max(int(header_row_1based) - 1, 0)
    with BytesIO(resp.content) as bio:
        return pd.read_excel(bio, header=header0)


# =============================
# Data prep
# =============================

def _make_unique_columns(cols: List[str]) -> List[str]:
    seen = {}
    out = []
    for c in cols:
        name = str(c).strip()
        if name == "" or name.lower() == "nan":
            name = "ì»¬ëŸ¼"
        if name not in seen:
            seen[name] = 0
            out.append(name)
        else:
            seen[name] += 1
            out.append(f"{name}__{seen[name]}")
    return out


def normalize_naver_datalab(df_raw: pd.DataFrame) -> pd.DataFrame:
    if df_raw is None or df_raw.empty:
        raise ValueError("ì‹œíŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    df = df_raw.copy()
    df.columns = _make_unique_columns(list(df.columns))

    # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸°
    date_col = "ë‚ ì§œ" if "ë‚ ì§œ" in df.columns else df.columns[0]
    df = df.dropna(subset=[date_col]).copy()

    s = df[date_col].astype(str).str.strip()
    # ì¼ë°˜ì ìœ¼ë¡œ 'YYYY-MM-DD' / 'YYYY.MM.DD' í˜¼ì¬ ê°€ëŠ¥
    # pandas ìµœì‹  ë²„ì „ì—ì„œ infer_datetime_formatì€ deprecated (ê¸°ë³¸ì´ strict parsing)
    dt = pd.to_datetime(s, errors="coerce")
    if dt.isna().all():
        dt = pd.to_datetime(s, errors="coerce", format="%Y.%m.%d")
    df = df[dt.notna()].copy()
    df["ë‚ ì§œ"] = dt[dt.notna()].dt.date.astype(str)  # YYYY-MM-DD

    # ìˆ«ì ë³€í™˜(ë‚ ì§œ ì œì™¸)
    for c in df.columns:
        if c == date_col or c == "ë‚ ì§œ":
            continue
        # ì¤‘ë³µ ì»¬ëŸ¼ì´ë©´ df[c]ê°€ DataFrameì´ ë  ìˆ˜ ìˆì–´ Seriesë¡œ ê³ ì •
        if isinstance(df[c], pd.DataFrame):
            df[c] = df[c].iloc[:, 0]
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # ì •ë¦¬: ë‚ ì§œë¥¼ ë§¨ ì•ìœ¼ë¡œ
    if date_col != "ë‚ ì§œ":
        df = df.drop(columns=[date_col])
    keep = ["ë‚ ì§œ"] + [c for c in df.columns if c != "ë‚ ì§œ"]
    df = df.loc[:, keep].copy()
    df = df.sort_values("ë‚ ì§œ")
    return df


def normalize_naver_datalab_comp(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    ë¹„êµ ì‹œíŠ¸ êµ¬ì¡°(ì˜ˆ):
    ë‚ ì§œ | êµ­ë‚´ì™€ì¸ | ë‚ ì§œ | ì™¸êµ­ì™€ì¸ | ë‚ ì§œ | í”„ë‘ìŠ¤ì™€ì¸ | ë‚ ì§œ | ì´íƒœë¦¬ì™€ì¸ | ë‚ ì§œ | ì¹ ë ˆì™€ì¸
    """
    if df_raw is None or df_raw.empty:
        raise ValueError("ì‹œíŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    df = df_raw.copy()
    # pandasê°€ ì¤‘ë³µ ì»¬ëŸ¼ì„ 'ë‚ ì§œ.1'ì²˜ëŸ¼ ë§Œë“¤ ìˆ˜ ìˆì–´ '.ìˆ«ì' ì œê±° í›„ uniqueí™”
    df.columns = _make_unique_columns([re.sub(r"\.\d+$", "", str(c)).strip() for c in df.columns])

    expected_terms = ["êµ­ë‚´ì™€ì¸", "ì™¸êµ­ì™€ì¸", "í”„ë‘ìŠ¤ì™€ì¸", "ì´íƒœë¦¬ì™€ì¸", "ì¹ ë ˆì™€ì¸"]

    # ì»¬ëŸ¼ëª…ì´ ê¹¨ì ¸ ë“¤ì–´ì˜¤ëŠ” í™˜ê²½ë„ ìˆì–´(ì½˜ì†”/ë¡œì¼€ì¼ ì´ìŠˆ), ìš°ì„  "ì˜ë„ëœ ìœ„ì¹˜" ê¸°ë°˜ìœ¼ë¡œ ë³µêµ¬ ì‹œë„
    # í˜•íƒœ: [ë‚ ì§œ, v1, ë‚ ì§œ, v2, ë‚ ì§œ, v3, ë‚ ì§œ, v4, ë‚ ì§œ, v5]
    if not all(c in df.columns for c in expected_terms):
        if df.shape[1] >= 10:
            positional = [df.columns[1], df.columns[3], df.columns[5], df.columns[7], df.columns[9]]
            tmp = df.loc[:, [df.columns[0]] + positional].copy()
            tmp.columns = ["ë‚ ì§œ"] + expected_terms
            df = tmp
        else:
            missing = [c for c in expected_terms if c not in df.columns]
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {missing} (í˜„ì¬ ì»¬ëŸ¼ ìˆ˜: {df.shape[1]})")

    date_col = "ë‚ ì§œ" if "ë‚ ì§œ" in df.columns else df.columns[0]
    df = df.dropna(subset=[date_col]).copy()

    s = df[date_col].astype(str).str.strip()
    dt = pd.to_datetime(s, errors="coerce")
    if dt.isna().all():
        dt = pd.to_datetime(s, errors="coerce", format="%Y.%m.%d")
    df = df[dt.notna()].copy()
    df["ë‚ ì§œ"] = dt[dt.notna()].dt.date.astype(str)  # YYYY-MM-DD

    # ìˆ«ì ë³€í™˜(ëŒ€ìƒ 5ê°œë§Œ)
    for c in expected_terms:
        if isinstance(df[c], pd.DataFrame):
            df[c] = df[c].iloc[:, 0]
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)

    keep = ["ë‚ ì§œ"] + expected_terms
    df = df.loc[:, keep].copy()
    df = df.sort_values("ë‚ ì§œ")
    return df


def aggregate(df: pd.DataFrame, freq: str) -> pd.DataFrame:
    """
    freq: 'D' | 'M' | 'Y'
    """
    out = df.copy()
    out["ë‚ ì§œ_dt"] = pd.to_datetime(out["ë‚ ì§œ"], errors="coerce")
    out = out[out["ë‚ ì§œ_dt"].notna()].copy()

    numeric_cols = [c for c in out.columns if c not in {"ë‚ ì§œ", "ë‚ ì§œ_dt"}]
    for c in numeric_cols:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0.0)

    if freq == "D":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.strftime("%Y-%m-%d")
    elif freq == "M":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.to_period("M").astype(str)  # YYYY-MM
    elif freq == "Y":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.year.astype(int).astype(str)
    else:
        raise ValueError("freqëŠ” 'D','M','Y' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    g = out.groupby("ê¸°ê°„", as_index=False)[numeric_cols].sum()
    cols = ["ê¸°ê°„"] + numeric_cols
    return g.loc[:, cols].copy()


def plot_trend(df: pd.DataFrame, x_col: str, y_cols: List[str], title: str) -> go.Figure:
    fig = go.Figure()
    for c in y_cols:
        fig.add_trace(
            go.Scatter(
                x=df[x_col],
                y=df[c],
                mode="lines+markers",
                name=c,
                line=dict(width=3),
                marker=dict(size=5),
            )
        )
    fig.update_layout(
        title=title,
        height=520,
        margin=dict(l=30, r=20, t=60, b=40),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
        font=dict(family=_CHOSEN_FONT or "Malgun Gothic", size=14),
    )
    fig.update_xaxes(showgrid=False)
    fig.update_yaxes(showgrid=True, gridcolor="rgba(0,0,0,0.08)")
    return fig


# =============================
# Streamlit UI
# =============================

st.set_page_config(page_title="ì˜ë™ì™€ì¸ ë¹…ë°ì´í„°(íŠ¸ë Œë“œ)_NaverDatalab", layout="wide")
inject_noto_sans_kr()
st.title("ğŸ“ˆ Naver DataLab íŠ¸ë Œë“œ ë¶„ì„")

with st.sidebar:
    st.header("ë©”ë‰´")
    menu = st.radio("ë³´ê¸°", ["naver datalab trend", "naver datalab comp"], index=0)
    st.divider()

    st.header("ë°ì´í„° ì†ŒìŠ¤")
    if menu == "naver datalab trend":
        sheet_url = st.text_input("êµ¬ê¸€ì‹œíŠ¸ URL", value=DEFAULT_SHEET_URL)
    else:
        sheet_url = st.text_input("êµ¬ê¸€ì‹œíŠ¸ URL", value=DEFAULT_COMP_SHEET_URL)
    st.caption("ê³µê°œ/ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì ë³´ê¸° ê°€ëŠ¥'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.divider()

    st.header("ì‹œê°í™” ì„¤ì •")
    default_metric = "í•©ê³„"
    st.caption(f"í•œê¸€ í°íŠ¸: {_CHOSEN_FONT or 'ê°ì§€ ì‹¤íŒ¨(ê¹¨ì§ ì‹œ ë§‘ì€ ê³ ë”•/ë‚˜ëˆ”ê³ ë”• ì„¤ì¹˜ í•„ìš”)'}")


@st.cache_data(show_spinner=True)
def load_and_prepare(url: str) -> pd.DataFrame:
    raw = fetch_xlsx_as_df(url)
    return normalize_naver_datalab(raw)


@st.cache_data(show_spinner=True)
def load_and_prepare_comp(url: str) -> pd.DataFrame:
    # 7í–‰: í•„ë“œëª…, 8í–‰ë¶€í„° ë°ì´í„°
    raw = fetch_xlsx_as_df_with_header(url, header_row_1based=7)
    return normalize_naver_datalab_comp(raw)


try:
    if menu == "naver datalab trend":
        df = load_and_prepare(sheet_url)
    else:
        df = load_and_prepare_comp(sheet_url)
except Exception as e:
    st.error(f"êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

st.caption(f"ì—…ë°ì´íŠ¸ë¨: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

numeric_candidates = [c for c in df.columns if c != "ë‚ ì§œ"]
if not numeric_candidates:
    st.error("ìˆ«ì ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë‚ ì§œ ì™¸ì— ë¶„ì„í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤)")
    st.stop()

if menu == "naver datalab trend":
    with st.sidebar:
        y_cols = st.multiselect(
            "í‘œì‹œí•  ì§€í‘œ(ë³µìˆ˜ ì„ íƒ)",
            options=numeric_candidates,
            default=[default_metric] if default_metric in numeric_candidates else [numeric_candidates[-1]],
        )

    if not y_cols:
        st.warning("í‘œì‹œí•  ì§€í‘œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    tab_d, tab_m, tab_y = st.tabs(["ì¼ë³„", "ì›”ë³„", "ë…„ë„ë³„"])

    with tab_d:
        st.subheader("ì¼ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
        df_d = aggregate(df, "D")
        fig = plot_trend(df_d, "ê¸°ê°„", y_cols, "ì¼ë³„ íŠ¸ë Œë“œ")
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("ë°ì´í„° ë³´ê¸°"):
            st.dataframe(df_d, use_container_width=True, height=360)

    with tab_m:
        st.subheader("ì›”ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
        df_m = aggregate(df, "M")
        fig = plot_trend(df_m, "ê¸°ê°„", y_cols, "ì›”ë³„ íŠ¸ë Œë“œ")
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("ë°ì´í„° ë³´ê¸°"):
            st.dataframe(df_m, use_container_width=True, height=360)

    with tab_y:
        st.subheader("ë…„ë„ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
        df_y = aggregate(df, "Y")
        fig = plot_trend(df_y, "ê¸°ê°„", y_cols, "ë…„ë„ë³„ íŠ¸ë Œë“œ")
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("ë°ì´í„° ë³´ê¸°"):
            st.dataframe(df_y, use_container_width=True, height=360)

else:
    default_terms = ["êµ­ë‚´ì™€ì¸", "ì™¸êµ­ì™€ì¸", "í”„ë‘ìŠ¤ì™€ì¸", "ì´íƒœë¦¬ì™€ì¸", "ì¹ ë ˆì™€ì¸"]
    with st.sidebar:
        y_cols = st.multiselect(
            "í‘œì‹œí•  í‚¤ì›Œë“œ(ë³µìˆ˜ ì„ íƒ)",
            options=numeric_candidates,
            default=[c for c in default_terms if c in numeric_candidates] or numeric_candidates,
        )

    if not y_cols:
        st.warning("í‘œì‹œí•  í‚¤ì›Œë“œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        st.stop()

    tab_m, tab_y = st.tabs(["ì›”ë³„", "ë…„ë„ë³„"])

    with tab_m:
        st.subheader("ì›”ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ (êµ­ë‚´/ì™¸êµ­/êµ­ê°€ë³„)")
        df_m = aggregate(df, "M")
        fig = plot_trend(df_m, "ê¸°ê°„", y_cols, "ì›”ë³„ íŠ¸ë Œë“œ (ë¹„êµ)")
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("ë°ì´í„° ë³´ê¸°"):
            st.dataframe(df_m, use_container_width=True, height=360)

    with tab_y:
        st.subheader("ë…„ë„ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ (êµ­ë‚´/ì™¸êµ­/êµ­ê°€ë³„)")
        df_y = aggregate(df, "Y")
        fig = plot_trend(df_y, "ê¸°ê°„", y_cols, "ë…„ë„ë³„ íŠ¸ë Œë“œ (ë¹„êµ)")
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("ë°ì´í„° ë³´ê¸°"):
            st.dataframe(df_y, use_container_width=True, height=360)


