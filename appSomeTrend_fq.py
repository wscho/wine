import os
import re
import time
from datetime import datetime
from io import BytesIO
from typing import Optional, List

import pandas as pd
import requests
import streamlit as st

import plotly.graph_objects as go

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

from korean_font import configure_korean_font
from web_fonts import inject_noto_sans_kr


# =============================
# Font (Korean)
# =============================
_CHOSEN_FONT = configure_korean_font().name


# =============================
# Google Sheets (XLSX download)
# =============================

# 2_ì¸íŠ¸ë Œë“œ_ì–¸ê¸‰ëŸ‰í†µí•©
DEFAULT_SHEET_URL = "https://docs.google.com/spreadsheets/d/1nFm0GmXTXz_xXPY2lRO4cPB9PjAF-vRw6jbCK5VnmKQ/edit?usp=sharing"


def _extract_spreadsheet_id(url: str) -> str:
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", url)
    if not m:
        raise ValueError("êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ URLì—ì„œ ë¬¸ì„œ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return m.group(1)


def _xlsx_export_url(spreadsheet_id: str) -> str:
    return f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx"


def _is_probably_html(resp: requests.Response) -> bool:
    ctype = (resp.headers.get("Content-Type") or "").lower()
    if "text/html" in ctype:
        return True
    head = resp.content[:200].lstrip().lower()
    return head.startswith(b"<!doctype html") or head.startswith(b"<html")


def download_with_retry(url: str, timeout_s: int = 30, retries: int = 3, backoff_s: float = 0.8) -> requests.Response:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    }
    last_exc: Optional[Exception] = None
    for i in range(retries):
        try:
            resp = requests.get(url, headers=headers, timeout=timeout_s, allow_redirects=True)
            resp.raise_for_status()
            if _is_probably_html(resp):
                raise ValueError("ì‘ë‹µì´ HTMLì…ë‹ˆë‹¤(ê¶Œí•œ/ê³µê°œ ì„¤ì • ë¬¸ì œ ê°€ëŠ¥).")
            return resp
        except Exception as e:
            last_exc = e
            time.sleep(backoff_s * (2**i))
    raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {last_exc}")


@st.cache_data(show_spinner=False)
def fetch_xlsx_raw(sheet_url: str) -> pd.DataFrame:
    """
    ì£¼ì˜: ì´ ì‹œíŠ¸ëŠ” 1~13í–‰ì´ ì£¼ì„, 14í–‰ì´ í—¤ë”, 15í–‰ë¶€í„° ë°ì´í„°ì´ë¯€ë¡œ header=None ë¡œ ì½ì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    sid = _extract_spreadsheet_id(sheet_url)
    resp = download_with_retry(_xlsx_export_url(sid))
    with BytesIO(resp.content) as bio:
        return pd.read_excel(bio, header=None)


# =============================
# Parsing / Aggregation
# =============================

def _make_unique_columns(cols: List[str]) -> List[str]:
    seen: dict[str, int] = {}
    out: List[str] = []
    for c in cols:
        name = str(c).strip()
        if name == "" or name.lower() == "nan":
            name = "ì»¬ëŸ¼"
        if name not in seen:
            seen[name] = 0
            out.append(name)
        else:
            seen[name] += 1
            out.append(f"{name}__{seen[name]}")
    return out


def parse_sometrend_freq(df_raw: pd.DataFrame) -> pd.DataFrame:
    # 1~13í–‰ ë¬´ì‹œ, 14í–‰ í—¤ë”, 15í–‰ë¶€í„° ë°ì´í„°
    if df_raw is None or df_raw.empty:
        raise ValueError("ì‹œíŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    if len(df_raw) < 15:
        raise ValueError("ì¸íŠ¸ë Œë“œ ë¹ˆë„ìˆ˜: ì‹œíŠ¸ í–‰ ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤(ìµœì†Œ 15í–‰).")

    header_idx = 13  # 14ë²ˆì§¸ ì¤„(0-based)
    data_start_idx = 14

    headers = df_raw.iloc[header_idx].tolist()
    headers = _make_unique_columns(headers)

    df = df_raw.iloc[data_start_idx:].copy()
    df.columns = headers
    # ì™„ì „ NaN ì»¬ëŸ¼ ì œê±°
    df = df.loc[:, [c for c in df.columns if str(c).lower() != "nan"]].copy()

    first_col = df.columns[0]
    df = df.dropna(subset=[first_col]).rename(columns={first_col: "ë‚ ì§œ"}).copy()

    # ë‚ ì§œ: 2014.01.01 -> 2014-01-01
    dt = pd.to_datetime(df["ë‚ ì§œ"].astype(str).str.strip(), format="%Y.%m.%d", errors="coerce")
    df = df[dt.notna()].copy()
    df["ë‚ ì§œ"] = dt.dt.strftime("%Y-%m-%d")

    # ìˆ«ì ë³€í™˜(ë‚ ì§œ ì œì™¸)
    for c in df.columns:
        if c == "ë‚ ì§œ":
            continue
        # ì¤‘ë³µ ì»¬ëŸ¼ì´ë©´ df[c]ê°€ DataFrameì´ ë  ìˆ˜ ìˆì–´ Seriesë¡œ ê³ ì •
        if isinstance(df[c], pd.DataFrame):
            df[c] = df[c].iloc[:, 0]
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)

    df = df.sort_values("ë‚ ì§œ")
    return df


def aggregate(df: pd.DataFrame, freq: str) -> pd.DataFrame:
    """
    freq: 'D' | 'M' | 'Y'
    """
    out = df.copy()
    out["ë‚ ì§œ_dt"] = pd.to_datetime(out["ë‚ ì§œ"], errors="coerce")
    out = out[out["ë‚ ì§œ_dt"].notna()].copy()

    numeric_cols = [c for c in out.columns if c not in {"ë‚ ì§œ", "ë‚ ì§œ_dt"}]
    for c in numeric_cols:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0.0)

    if freq == "D":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.strftime("%Y-%m-%d")
    elif freq == "M":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.to_period("M").astype(str)  # YYYY-MM
    elif freq == "Y":
        out["ê¸°ê°„"] = out["ë‚ ì§œ_dt"].dt.year.astype(int).astype(str)
    else:
        raise ValueError("freqëŠ” 'D','M','Y' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    g = out.groupby("ê¸°ê°„", as_index=False)[numeric_cols].sum()
    return g.loc[:, ["ê¸°ê°„"] + numeric_cols].copy()


def plot_trend(df: pd.DataFrame, x_col: str, y_cols: List[str], title: str) -> go.Figure:
    fig = go.Figure()
    for c in y_cols:
        fig.add_trace(
            go.Scatter(
                x=df[x_col],
                y=df[c],
                mode="lines+markers",
                name=c,
                line=dict(width=3),
                marker=dict(size=5),
            )
        )
    fig.update_layout(
        title=title,
        height=520,
        margin=dict(l=30, r=20, t=60, b=40),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
        font=dict(family=_CHOSEN_FONT or "Malgun Gothic", size=14),
    )
    fig.update_xaxes(showgrid=False)
    fig.update_yaxes(showgrid=True, gridcolor="rgba(0,0,0,0.08)")
    return fig


# =============================
# Streamlit UI
# =============================

st.set_page_config(page_title="ì¸íŠ¸ë Œë“œ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ", layout="wide")
inject_noto_sans_kr()
st.title("ğŸ“ˆ ì¸íŠ¸ë Œë“œ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")

with st.sidebar:
    st.header("ë°ì´í„° ì†ŒìŠ¤")
    sheet_url = st.text_input("êµ¬ê¸€ì‹œíŠ¸ URL", value=DEFAULT_SHEET_URL)
    st.caption("ê³µê°œ/ê³µìœ  ì„¤ì •ì´ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì ë³´ê¸° ê°€ëŠ¥'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    st.divider()

    st.header("ì‹œê°í™” ì„¤ì •")
    st.caption(f"í•œê¸€ í°íŠ¸: {_CHOSEN_FONT or 'ê°ì§€ ì‹¤íŒ¨(ê¹¨ì§ ì‹œ ë§‘ì€ ê³ ë”•/ë‚˜ëˆ”ê³ ë”• ì„¤ì¹˜ í•„ìš”)'}")


@st.cache_data(show_spinner=True)
def load_and_prepare(url: str) -> pd.DataFrame:
    raw = fetch_xlsx_raw(url)
    return parse_sometrend_freq(raw)


try:
    df = load_and_prepare(sheet_url)
except Exception as e:
    st.error(f"êµ¬ê¸€ì‹œíŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

st.caption(f"ì—…ë°ì´íŠ¸ë¨: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

numeric_candidates = [c for c in df.columns if c != "ë‚ ì§œ"]
if not numeric_candidates:
    st.error("ìˆ«ì ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë‚ ì§œ ì™¸ì— ë¶„ì„í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤)")
    st.stop()

preferred_defaults = ["í•©ê³„", "ì»¤ë®¤ë‹ˆí‹°", "ì¸ìŠ¤íƒ€ê·¸ë¨", "ë¸”ë¡œê·¸", "ë‰´ìŠ¤", "X(íŠ¸ìœ„í„°)"]
default_y = [c for c in preferred_defaults if c in numeric_candidates]
if not default_y:
    default_y = [numeric_candidates[0]]

with st.sidebar:
    y_cols = st.multiselect(
        "í‘œì‹œí•  ì§€í‘œ(ë³µìˆ˜ ì„ íƒ)",
        options=numeric_candidates,
        default=default_y,
    )

if not y_cols:
    st.warning("í‘œì‹œí•  ì§€í‘œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
    st.stop()

tab_d, tab_m, tab_y = st.tabs(["ì¼ë³„", "ì›”ë³„", "ë…„ë„ë³„"])

with tab_d:
    st.subheader("ì¼ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
    df_d = aggregate(df, "D")
    st.plotly_chart(plot_trend(df_d, "ê¸°ê°„", y_cols, "ì¼ë³„ íŠ¸ë Œë“œ"), use_container_width=True)
    with st.expander("ë°ì´í„° ë³´ê¸°"):
        st.dataframe(df_d, use_container_width=True, height=360)

with tab_m:
    st.subheader("ì›”ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
    df_m = aggregate(df, "M")
    st.plotly_chart(plot_trend(df_m, "ê¸°ê°„", y_cols, "ì›”ë³„ íŠ¸ë Œë“œ"), use_container_width=True)
    with st.expander("ë°ì´í„° ë³´ê¸°"):
        st.dataframe(df_m, use_container_width=True, height=360)

with tab_y:
    st.subheader("ë…„ë„ë³„ ì–¸ê¸‰ëŸ‰ íŠ¸ë Œë“œ")
    df_y = aggregate(df, "Y")
    st.plotly_chart(plot_trend(df_y, "ê¸°ê°„", y_cols, "ë…„ë„ë³„ íŠ¸ë Œë“œ"), use_container_width=True)
    with st.expander("ë°ì´í„° ë³´ê¸°"):
        st.dataframe(df_y, use_container_width=True, height=360)


